{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54fba428-1cb6-4d95-920d-c6e27d590d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient for importing modules from the parent directory\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddd7462-37e4-493a-9d36-da78af660d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/aum/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import src.models as models\n",
    "from src import dataloader\n",
    "from src.utilities.stats import calculate_stats\n",
    "from IPython.display import Audio, display\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb60b0c-4536-4c2f-acab-9a728fae4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments about the data\n",
    "data_args = Namespace(\n",
    "    num_mel_bins = 128,\n",
    "    target_length = 1024,\n",
    "    mean = -5.0767093,\n",
    "    std = 4.4533687,\n",
    ")\n",
    "\n",
    "# Arguments about the model\n",
    "model_args = Namespace(\n",
    "    model_type = 'base',\n",
    "    n_classes = 309,\n",
    "    imagenet_pretrain = False,\n",
    "    imagenet_pretrain_path = None,\n",
    "    aum_pretrain = True,\n",
    "    aum_pretrain_path = 'models/aum-base_audioset-vggsound.pth',\n",
    "    aum_variant = 'Fo-Bi',\n",
    "    device = 'cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c443ff-f91d-4e15-8e43-00e16a1544cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Resize function is resample_patch_embed\n",
      "Initializing FlexiPatchEmbed with the following parameters:\n",
      "patch_size=(16, 16), in_chans=1, embed_dim=768, bias=True, norm_layer=None, flatten=True, proj_load=yes, resize_func=resample_patch_embed\n",
      "The resize function is resample_patch_embed\n",
      "Loading projection weights!\n",
      "The shapes of the current projection: bias=torch.Size([768]), weight=torch.Size([768, 1, 16, 16])\n",
      "The shapes of the loaded projection: bias=torch.Size([768]), weight=torch.Size([768, 1, 16, 16])\n",
      "Initializing FlexiPosEmbed with the following parameters:\n",
      "input_size=(128, 1024), pos_grid_size=(8, 64), embed_dim=768, pos_embed_load=torch.Size([1, 513, 768]), pos_grid_size_load=(8, 64), n_prefix_tokens=1, pos_embed_prefix=True\n",
      "Loading position embedding!\n",
      "The shape of the current grid size: (8, 64)\n",
      "The shape of the loaded grid size: (8, 64)\n"
     ]
    }
   ],
   "source": [
    "# Initilize the model\n",
    "\n",
    "# Embedding dimension\n",
    "if 'base' in model_args.model_type:\n",
    "    embed_dim = 768\n",
    "elif 'small' in model_args.model_type:\n",
    "    embed_dim = 384\n",
    "elif 'tiny' in model_args.model_type:\n",
    "    embed_dim = 192\n",
    "\n",
    "# AuM block type\n",
    "bimamba_type = {\n",
    "    'Fo-Fo': 'none', \n",
    "    'Fo-Bi': 'v1', \n",
    "    'Bi-Bi': 'v2'\n",
    "}.get(\n",
    "    model_args.aum_variant, \n",
    "    None\n",
    ")\n",
    "\n",
    "AuM = models.AudioMamba(\n",
    "    spectrogram_size=(data_args.num_mel_bins, data_args.target_length),\n",
    "    patch_size=(16, 16),\n",
    "    strides=(16, 16),\n",
    "    embed_dim=embed_dim,\n",
    "    num_classes=model_args.n_classes,\n",
    "    imagenet_pretrain=model_args.imagenet_pretrain,\n",
    "    imagenet_pretrain_path=model_args.imagenet_pretrain_path,\n",
    "    aum_pretrain=model_args.aum_pretrain,\n",
    "    aum_pretrain_path=model_args.aum_pretrain_path,\n",
    "    bimamba_type=bimamba_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55b0294-aeb9-48bd-8f37-de6702396d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Resize function is resample_patch_embed\n",
      "Initializing FlexiPatchEmbed with the following parameters:\n",
      "patch_size=[16, 16], in_chans=1, embed_dim=768, bias=True, norm_layer=None, flatten=True, proj_load=yes, resize_func=resample_patch_embed\n",
      "The resize function is resample_patch_embed\n",
      "Loading projection weights!\n",
      "The shapes of the current projection: bias=torch.Size([768]), weight=torch.Size([768, 1, 16, 16])\n",
      "The shapes of the loaded projection: bias=torch.Size([768]), weight=torch.Size([768, 1, 16, 16])\n",
      "Initializing FlexiPosEmbed with the following parameters:\n",
      "input_size=[128, 1024], pos_grid_size=(8, 64), embed_dim=768, pos_embed_load=torch.Size([1, 513, 768]), pos_grid_size_load=(8, 64), n_prefix_tokens=1, pos_embed_prefix=True\n",
      "Loading position embedding!\n",
      "The shape of the current grid size: (8, 64)\n",
      "The shape of the loaded grid size: (8, 64)\n"
     ]
    }
   ],
   "source": [
    "model = AuM.from_pretrained(\"Robzy/audiomamba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c34c00-af9f-402f-a72c-0a6fd23c05ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aum",
   "language": "python",
   "name": "aum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
